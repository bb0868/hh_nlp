{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a63344f-a2f9-4ae9-a361-812e698436af",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Prepping Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32c2e002-38c8-452d-8052-d88975ad426a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbd091aa-4491-4f6e-b526-481748b4783d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, load_dataset\n",
    "import pandas as pd\n",
    "df = pd.read_csv('/notebooks/data/curated_hh.csv')\n",
    "\n",
    "#, nrows=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca7ae7d4-6988-49f7-91e6-7126a9e37fbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>album</th>\n",
       "      <th>song</th>\n",
       "      <th>typed_by</th>\n",
       "      <th>url</th>\n",
       "      <th>lyric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chi Ali f/ Vanilli Shake</td>\n",
       "      <td>The Fabulous Chi-Ali</td>\n",
       "      <td>Chi-Ali vs. Vanilli Shake</td>\n",
       "      <td>malbojha666@hotmail.com</td>\n",
       "      <td>https://ohhla.com/anonymous/chi_ali/fabulous/v...</td>\n",
       "      <td>(Vanilli Shake)\\nI glide into this, clench fis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Chi-Ali</td>\n",
       "      <td>Let the Horns Blow 12\"</td>\n",
       "      <td>Funky Lemonade (Remix)</td>\n",
       "      <td>scott_rodkey@hotmail.com</td>\n",
       "      <td>https://ohhla.com/anonymous/chi_ali/rm_bside/l...</td>\n",
       "      <td>Aw yeah, it's the Fabulous Chi-Ali coming at...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chi-Ali</td>\n",
       "      <td>Roadrunner 12\"</td>\n",
       "      <td>Roadrunner (Puberty Mix)</td>\n",
       "      <td>scott_rodkey@hotmail.com</td>\n",
       "      <td>https://ohhla.com/anonymous/chi_ali/rm_bside/r...</td>\n",
       "      <td>Chi-Ali the lady stunner, I'm stunning the stu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Child Rebel Soldier (Kanye West, Lupe Fiasco, ...</td>\n",
       "      <td>Don't Stop! 12\"</td>\n",
       "      <td>Don't Stop!</td>\n",
       "      <td>newos_crib_is@hotmail.com</td>\n",
       "      <td>https://ohhla.com/anonymous/childreb/rm_bside/...</td>\n",
       "      <td>[Pharrell]\\nUh, what?\\nExplain yourself, how y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Child Rebel Soldier (Kanye West, Lupe Fiasco, ...</td>\n",
       "      <td>Us Placers 12\"</td>\n",
       "      <td>Us Placers</td>\n",
       "      <td>newos_crib_is@hotmail.com</td>\n",
       "      <td>https://ohhla.com/anonymous/childreb/rm_bside/...</td>\n",
       "      <td>[Lupe Fiasco]\\nYeah, just a little bit, just a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1590</th>\n",
       "      <td>Chi-Ali</td>\n",
       "      <td>The Fabulous Chi-Ali</td>\n",
       "      <td>Age Ain't Nothing But a #</td>\n",
       "      <td>scott_rodkey@hotmail.com</td>\n",
       "      <td>https://ohhla.com/anonymous/chi_ali/fabulous/a...</td>\n",
       "      <td>Chorus: KRS-One sample\\n\\n\"Girls look soooo go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1591</th>\n",
       "      <td>Chi-Ali f/ Dove (De La Soul), Dres, Phife, Fas...</td>\n",
       "      <td>The Fabulous Chi-Ali</td>\n",
       "      <td>Let the Horns Blow</td>\n",
       "      <td>scott_rodkey@hotmail.com</td>\n",
       "      <td>https://ohhla.com/anonymous/chi_ali/fabulous/h...</td>\n",
       "      <td>[Dres]\\nYo! One for your mother, two for your ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1592</th>\n",
       "      <td>Chi-Ali</td>\n",
       "      <td>The Fabulous Chi-Ali</td>\n",
       "      <td>Funky Lemonade</td>\n",
       "      <td>scott_rodkey@hotmail.com</td>\n",
       "      <td>https://ohhla.com/anonymous/chi_ali/fabulous/l...</td>\n",
       "      <td>\"Cool in the shade, drink a little bit of le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1593</th>\n",
       "      <td>Chi-Ali</td>\n",
       "      <td>The Fabulous Chi-Ali</td>\n",
       "      <td>Looped It</td>\n",
       "      <td>scott_rodkey@hotmail.com</td>\n",
       "      <td>https://ohhla.com/anonymous/chi_ali/fabulous/l...</td>\n",
       "      <td>This ain't a twinkle twinkle little star\\nBut ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>Chi-Ali f/ Dove</td>\n",
       "      <td>The Fabulous Chi-Ali</td>\n",
       "      <td>Roadrunner</td>\n",
       "      <td>scott_rodkey@hotmail.com</td>\n",
       "      <td>https://ohhla.com/anonymous/chi_ali/fabulous/r...</td>\n",
       "      <td>Verse 1: Chi-Ali\\n\\nI be the Chi, oh who I be\\...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1595 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 artist  \\\n",
       "0                              Chi Ali f/ Vanilli Shake   \n",
       "1                                               Chi-Ali   \n",
       "2                                               Chi-Ali   \n",
       "3     Child Rebel Soldier (Kanye West, Lupe Fiasco, ...   \n",
       "4     Child Rebel Soldier (Kanye West, Lupe Fiasco, ...   \n",
       "...                                                 ...   \n",
       "1590                                            Chi-Ali   \n",
       "1591  Chi-Ali f/ Dove (De La Soul), Dres, Phife, Fas...   \n",
       "1592                                            Chi-Ali   \n",
       "1593                                            Chi-Ali   \n",
       "1594                                    Chi-Ali f/ Dove   \n",
       "\n",
       "                       album                       song  \\\n",
       "0       The Fabulous Chi-Ali  Chi-Ali vs. Vanilli Shake   \n",
       "1     Let the Horns Blow 12\"     Funky Lemonade (Remix)   \n",
       "2             Roadrunner 12\"   Roadrunner (Puberty Mix)   \n",
       "3            Don't Stop! 12\"                Don't Stop!   \n",
       "4             Us Placers 12\"                 Us Placers   \n",
       "...                      ...                        ...   \n",
       "1590    The Fabulous Chi-Ali  Age Ain't Nothing But a #   \n",
       "1591    The Fabulous Chi-Ali         Let the Horns Blow   \n",
       "1592    The Fabulous Chi-Ali             Funky Lemonade   \n",
       "1593    The Fabulous Chi-Ali                  Looped It   \n",
       "1594    The Fabulous Chi-Ali                 Roadrunner   \n",
       "\n",
       "                       typed_by  \\\n",
       "0       malbojha666@hotmail.com   \n",
       "1      scott_rodkey@hotmail.com   \n",
       "2      scott_rodkey@hotmail.com   \n",
       "3     newos_crib_is@hotmail.com   \n",
       "4     newos_crib_is@hotmail.com   \n",
       "...                         ...   \n",
       "1590   scott_rodkey@hotmail.com   \n",
       "1591   scott_rodkey@hotmail.com   \n",
       "1592   scott_rodkey@hotmail.com   \n",
       "1593   scott_rodkey@hotmail.com   \n",
       "1594   scott_rodkey@hotmail.com   \n",
       "\n",
       "                                                    url  \\\n",
       "0     https://ohhla.com/anonymous/chi_ali/fabulous/v...   \n",
       "1     https://ohhla.com/anonymous/chi_ali/rm_bside/l...   \n",
       "2     https://ohhla.com/anonymous/chi_ali/rm_bside/r...   \n",
       "3     https://ohhla.com/anonymous/childreb/rm_bside/...   \n",
       "4     https://ohhla.com/anonymous/childreb/rm_bside/...   \n",
       "...                                                 ...   \n",
       "1590  https://ohhla.com/anonymous/chi_ali/fabulous/a...   \n",
       "1591  https://ohhla.com/anonymous/chi_ali/fabulous/h...   \n",
       "1592  https://ohhla.com/anonymous/chi_ali/fabulous/l...   \n",
       "1593  https://ohhla.com/anonymous/chi_ali/fabulous/l...   \n",
       "1594  https://ohhla.com/anonymous/chi_ali/fabulous/r...   \n",
       "\n",
       "                                                  lyric  \n",
       "0     (Vanilli Shake)\\nI glide into this, clench fis...  \n",
       "1       Aw yeah, it's the Fabulous Chi-Ali coming at...  \n",
       "2     Chi-Ali the lady stunner, I'm stunning the stu...  \n",
       "3     [Pharrell]\\nUh, what?\\nExplain yourself, how y...  \n",
       "4     [Lupe Fiasco]\\nYeah, just a little bit, just a...  \n",
       "...                                                 ...  \n",
       "1590  Chorus: KRS-One sample\\n\\n\"Girls look soooo go...  \n",
       "1591  [Dres]\\nYo! One for your mother, two for your ...  \n",
       "1592    \"Cool in the shade, drink a little bit of le...  \n",
       "1593  This ain't a twinkle twinkle little star\\nBut ...  \n",
       "1594  Verse 1: Chi-Ali\\n\\nI be the Chi, oh who I be\\...  \n",
       "\n",
       "[1595 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e38e128-95c7-4843-8e0c-38e069681fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#targeting the key variables for training\n",
    "df_lyrics = df[['artist','album','song','lyric']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b4c23a3-7c9d-4507-83fe-fe5e532082d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning dataset where there are no lyrics in a dataset\n",
    "df_lyrics= df_lyrics[df_lyrics['lyric']!=None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af2a4ef3-8bbb-48a3-844a-31c0ddfa54eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>album</th>\n",
       "      <th>song</th>\n",
       "      <th>lyric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1595</td>\n",
       "      <td>1595</td>\n",
       "      <td>1595</td>\n",
       "      <td>1595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>662</td>\n",
       "      <td>496</td>\n",
       "      <td>1567</td>\n",
       "      <td>1591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Curren$y</td>\n",
       "      <td>A Wolf in Sheep's Clothing</td>\n",
       "      <td>The Truth</td>\n",
       "      <td>* send corrections to the typist\\n\\n[KRS-One]\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>84</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          artist                       album       song  \\\n",
       "count       1595                        1595       1595   \n",
       "unique       662                         496       1567   \n",
       "top     Curren$y  A Wolf in Sheep's Clothing  The Truth   \n",
       "freq          84                          20          2   \n",
       "\n",
       "                                                    lyric  \n",
       "count                                                1595  \n",
       "unique                                               1591  \n",
       "top     * send corrections to the typist\\n\\n[KRS-One]\\...  \n",
       "freq                                                    2  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#review how many rows have been deleted\n",
    "df_lyrics.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0beda46-0b4e-4237-b81f-9463282a970f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping duplicate rows\n",
    "df_lyrics= df_lyrics[df_lyrics['lyric']!=None].drop_duplicates(subset=['lyric'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f75896b-44a8-4d50-a8d0-fdb5b134742a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping rows with null values\n",
    "df_lyrics = df_lyrics.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d578a886-67cf-4bbb-b04b-910e46bcec7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>album</th>\n",
       "      <th>song</th>\n",
       "      <th>lyric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1591</td>\n",
       "      <td>1591</td>\n",
       "      <td>1591</td>\n",
       "      <td>1591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>662</td>\n",
       "      <td>496</td>\n",
       "      <td>1567</td>\n",
       "      <td>1591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Curren$y</td>\n",
       "      <td>A Wolf in Sheep's Clothing</td>\n",
       "      <td>Clockwork</td>\n",
       "      <td>(Vanilli Shake)\\nI glide into this, clench fis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>84</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          artist                       album       song  \\\n",
       "count       1591                        1591       1591   \n",
       "unique       662                         496       1567   \n",
       "top     Curren$y  A Wolf in Sheep's Clothing  Clockwork   \n",
       "freq          84                          20          2   \n",
       "\n",
       "                                                    lyric  \n",
       "count                                                1591  \n",
       "unique                                               1591  \n",
       "top     (Vanilli Shake)\\nI glide into this, clench fis...  \n",
       "freq                                                    1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking to see how many rows have been deleted after cleaning\n",
    "df_lyrics.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a189166b-6341-4fb2-aa56-56cc3a07a21d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "artist                                  Digital Underground\n",
       "album                                         Future Rhythm\n",
       "song                                          Future Rhythm\n",
       "lyric     Hit em with the rhythm of the future x4\\n\\n[Kr...\n",
       "Name: 565, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lyrics.iloc[564]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74b21fd7-8b58-4f20-8c57-e9bc8b1cca18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"A little high belongs to you . . .\\n- Yeah, getting high off the soup, (drink it up)\\nA little high belongs to me . . .\\n- Top rhyming's how we're coming with the loop, (sip it down)\\nA little high belongs to you . . .\\n- A dab of this, dab of that, not too heavy on the garlic, (take it easy)\\nA little high belongs to me . . .\\n- With just a touch of oregano . . .\\n\\nNow everybody's funking but they don't know how\\nThey wasn't down back when the bull funked the cow\\nBut the chest of the cow was vestless\\nSo the stank from the D-thang bang left the breathless\\nOregano flow\\nDon't waste your time sticking out your chest, for no\\nReason: its the season for the lovely flow:\\nThe 'D', we're sick enough of stress, let it go\\nNow follow as I slip into the butter melody\\nThis is the part I take your heart and leave your vision blurry\\nSo try to focus on my dope\\nAnd I suggest you invest in a telescope;\\nAs I'm kicking hella rhythm, move closer to your television\\nCatch a look just like a hooker catch j-izm\\nEven with bifocals for your ears, you still couldn't see me though\\nAs I flavour up this vide' like oregano:\\nSlinging them nouns and verbs\\nYou couldn't see me with binoculars\\nI guess I'm kind of different cause I do love them hoes\\nOnly not the same way that I love my niggaroes\\nCause I love it when they say something fly\\nThe ill caps make me laugh till I cry\\nSome fries and some freaks and it's on, all night long\\nI love to see my homies living strong\\nBut that cook with the cloudy cookbook \\nrained salt on another brother's sunny day\\nI wonder are we really happy here with this lonely G game we play\\n\\nA little high belongs to you . . .\\n- Yeah, getting high off the soup, (drink it up)\\nA little high belongs to me . . .\\n- Top rhyming's how we're coming with the loop, (sip it down)\\nA little high belongs to you . . .\\n- A dab of this, dab of that, not too heavy on the garlic, (take it easy)\\nA little high belongs to me . . .\\n- With just a touch of oregano . . .\\n\\nNow everybody's looking but they cannot see\\nThe 'D' because we're future and we're too slippery\\nYou know we're coming with oregano flow\\nDon't waste your time sticking out your chest, for no\\nReason it's the season for the lovely flow:\\nThe 'D', we're sipping off the stress, let it go, let it go\\n\\nTop rhyming's how we're coming with the loops . . .\\nOregano, baby, oregano\\n\\nA little high belongs to you . . .\\n- Yeah, my soup'll get you high, (drink it up)\\nA little high belongs to me . . .\\n- Top rhyming's how we're coming, bye-bye\\nA little high belongs to you . . .\\nA little high belongs to me . . .\\n\\n\\n\\n\\n\\n\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lyrics[\"lyric\"][564]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d413b0f-2969-43d9-9547-1b44b122cbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Source - https://huggingface.co/docs/datasets/loading#pandas-dataframe\n",
    "#Source - https://huggingface.co/docs/datasets/v2.9.0/en/package_reference/loading_methods#datasets.load_dataset.split\n",
    "#maybe we need to split the data source during loading\n",
    "dataset = Dataset.from_pandas(df_lyrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1e63d4a9-4358-4b6e-a735-6e5c0adb12bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'artist': Value(dtype='string', id=None),\n",
       " 'album': Value(dtype='string', id=None),\n",
       " 'song': Value(dtype='string', id=None),\n",
       " 'lyric': Value(dtype='string', id=None),\n",
       " '__index_level_0__': Value(dtype='int64', id=None)}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "921ddefe-eb9d-4c19-b800-b66cde5e27cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'artist': Value(dtype='string', id=None),\n",
       " 'album': Value(dtype='string', id=None),\n",
       " 'lyric': Value(dtype='string', id=None),\n",
       " '__index_level_0__': Value(dtype='int64', id=None)}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset.remove_columns([\"song\"])\n",
    "dataset.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8d9821ab-bee7-4d28-aeff-b61753659114",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'album': Value(dtype='string', id=None),\n",
       " 'lyric': Value(dtype='string', id=None),\n",
       " '__index_level_0__': Value(dtype='int64', id=None)}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset.remove_columns([\"artist\"])\n",
    "dataset.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4b64da73-038e-46f0-b83c-681761be754b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'album': Value(dtype='string', id=None),\n",
       " 'lyric': Value(dtype='string', id=None)}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset.remove_columns([\"__index_level_0__\"])\n",
    "dataset.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "476c7e0d-a6cb-43d7-889f-312283097e79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lyric': Value(dtype='string', id=None)}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset.remove_columns([\"album\"])\n",
    "dataset.features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e002c64-b147-4ad3-a806-34f67c92eccd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "19375381-2cbe-4360-9658-bdadca985dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the data into train and test set\n",
    "#from sklearn.model_selection import train_test_split\n",
    "\n",
    "#ds_train, ds_test = train_test_split(dataset, test_size=0.2, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeaee7c0-ba32-4715-8041-43ca227ed81d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Build Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b0fe51b5-c30c-4290-988b-101f8467bad1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "049d9b13e2e04ad1b8e7dec3b94c27c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0495936384484dc994161e13d586af7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/0.99M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce15e9b858c84a37a4b9645d1021c748",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44dd11f0ebc04df69359728917b0fa64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.29M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs length: 5\n",
      "Input chunk lengths: [500, 500, 219, 500, 349]\n",
      "Chunk mapping: [0, 0, 0, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, DataCollatorWithPadding\n",
    "\n",
    "context_length = 500\n",
    "checkpoint = \"gpt2\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "\n",
    "outputs = tokenizer(\n",
    "    dataset[\"lyric\"][:2],\n",
    "    truncation=True,\n",
    "    max_length=context_length,\n",
    "    return_overflowing_tokens=True,\n",
    "    return_length=True,\n",
    ")\n",
    "\n",
    "print(f\"Input IDs length: {len(outputs['input_ids'])}\")\n",
    "print(f\"Input chunk lengths: {(outputs['length'])}\")\n",
    "print(f\"Chunk mapping: {outputs['overflow_to_sample_mapping']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8bdbc6e-fd3f-4fdd-ae1c-7519e3f6a1c1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# tokenize def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e4032202-f9df-4d32-a3c8-dc2dbc44f511",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'function'=<function tokenize at 0x7f41032bfee0> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9916bacf6eac4f07ac315511f520e5f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids'],\n",
       "    num_rows: 1735\n",
       "})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize(element):\n",
    "    outputs = tokenizer(\n",
    "        element[\"lyric\"],\n",
    "        truncation=True,\n",
    "        max_length=context_length,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_length=True,\n",
    "    )\n",
    "    input_batch = []\n",
    "    for length, input_ids in zip(outputs[\"length\"], outputs[\"input_ids\"]):\n",
    "        if length == context_length:\n",
    "            input_batch.append(input_ids)\n",
    "    return {\"input_ids\": input_batch}\n",
    "\n",
    "\n",
    "tokenized_datasets = dataset.map(\n",
    "    tokenize, batched=True, remove_columns=[\"lyric\"])\n",
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e316ba55-d4c9-47a1-b29c-880f2556581e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [30,\n",
       "  679,\n",
       "  1816,\n",
       "  866,\n",
       "  284,\n",
       "  21532,\n",
       "  370,\n",
       "  1371,\n",
       "  198,\n",
       "  2437,\n",
       "  89,\n",
       "  10755,\n",
       "  64,\n",
       "  12911,\n",
       "  12,\n",
       "  33,\n",
       "  30,\n",
       "  679,\n",
       "  1816,\n",
       "  866,\n",
       "  284,\n",
       "  509,\n",
       "  12,\n",
       "  13143,\n",
       "  198,\n",
       "  38101,\n",
       "  11,\n",
       "  11054,\n",
       "  5835,\n",
       "  0,\n",
       "  314,\n",
       "  4427,\n",
       "  345,\n",
       "  284,\n",
       "  257,\n",
       "  983,\n",
       "  286,\n",
       "  2401,\n",
       "  2879,\n",
       "  274,\n",
       "  198,\n",
       "  32,\n",
       "  983,\n",
       "  286,\n",
       "  7462,\n",
       "  34160,\n",
       "  408,\n",
       "  198,\n",
       "  198,\n",
       "  58,\n",
       "  26788,\n",
       "  12,\n",
       "  33,\n",
       "  60,\n",
       "  198,\n",
       "  40,\n",
       "  1053,\n",
       "  587,\n",
       "  17702,\n",
       "  3490,\n",
       "  8605,\n",
       "  1683,\n",
       "  1201,\n",
       "  314,\n",
       "  373,\n",
       "  257,\n",
       "  1200,\n",
       "  198,\n",
       "  1537,\n",
       "  26760,\n",
       "  3490,\n",
       "  8605,\n",
       "  1611,\n",
       "  286,\n",
       "  1067,\n",
       "  696,\n",
       "  616,\n",
       "  3918,\n",
       "  198,\n",
       "  42323,\n",
       "  510,\n",
       "  1088,\n",
       "  262,\n",
       "  19908,\n",
       "  484,\n",
       "  307,\n",
       "  1972,\n",
       "  502,\n",
       "  3024,\n",
       "  198,\n",
       "  12193,\n",
       "  12311,\n",
       "  340,\n",
       "  393,\n",
       "  407,\n",
       "  11,\n",
       "  616,\n",
       "  35685,\n",
       "  973,\n",
       "  284,\n",
       "  262,\n",
       "  2823,\n",
       "  198,\n",
       "  464,\n",
       "  22601,\n",
       "  286,\n",
       "  616,\n",
       "  3450,\n",
       "  11,\n",
       "  616,\n",
       "  6029,\n",
       "  11,\n",
       "  4859,\n",
       "  1517,\n",
       "  198,\n",
       "  1537,\n",
       "  588,\n",
       "  4502,\n",
       "  286,\n",
       "  262,\n",
       "  26411,\n",
       "  673,\n",
       "  550,\n",
       "  5876,\n",
       "  351,\n",
       "  262,\n",
       "  9628,\n",
       "  198,\n",
       "  58,\n",
       "  31646,\n",
       "  12,\n",
       "  38,\n",
       "  25,\n",
       "  8920,\n",
       "  673,\n",
       "  1257,\n",
       "  3364,\n",
       "  510,\n",
       "  262,\n",
       "  5202,\n",
       "  26398,\n",
       "  198,\n",
       "  10995,\n",
       "  11,\n",
       "  8290,\n",
       "  71,\n",
       "  11,\n",
       "  673,\n",
       "  3521,\n",
       "  470,\n",
       "  8156,\n",
       "  340,\n",
       "  198,\n",
       "  10434,\n",
       "  276,\n",
       "  7540,\n",
       "  12,\n",
       "  41938,\n",
       "  588,\n",
       "  257,\n",
       "  1336,\n",
       "  6147,\n",
       "  15224,\n",
       "  198,\n",
       "  37,\n",
       "  40923,\n",
       "  750,\n",
       "  262,\n",
       "  6155,\n",
       "  11,\n",
       "  4585,\n",
       "  11,\n",
       "  28379,\n",
       "  510,\n",
       "  616,\n",
       "  3072,\n",
       "  198,\n",
       "  46120,\n",
       "  550,\n",
       "  502,\n",
       "  739,\n",
       "  4334,\n",
       "  8452,\n",
       "  379,\n",
       "  616,\n",
       "  1363,\n",
       "  198,\n",
       "  26449,\n",
       "  284,\n",
       "  4100,\n",
       "  337,\n",
       "  505,\n",
       "  11,\n",
       "  3027,\n",
       "  10533,\n",
       "  616,\n",
       "  9970,\n",
       "  198,\n",
       "  42940,\n",
       "  278,\n",
       "  319,\n",
       "  616,\n",
       "  14263,\n",
       "  494,\n",
       "  287,\n",
       "  257,\n",
       "  299,\n",
       "  16406,\n",
       "  1310,\n",
       "  8216,\n",
       "  198,\n",
       "  8496,\n",
       "  345,\n",
       "  1016,\n",
       "  30,\n",
       "  6350,\n",
       "  345,\n",
       "  587,\n",
       "  30,\n",
       "  5338,\n",
       "  338,\n",
       "  6502,\n",
       "  30,\n",
       "  5338,\n",
       "  338,\n",
       "  13937,\n",
       "  33577,\n",
       "  30,\n",
       "  220,\n",
       "  198,\n",
       "  1537,\n",
       "  314,\n",
       "  836,\n",
       "  470,\n",
       "  766,\n",
       "  645,\n",
       "  5858,\n",
       "  11,\n",
       "  314,\n",
       "  1239,\n",
       "  1138,\n",
       "  262,\n",
       "  39797,\n",
       "  198,\n",
       "  40,\n",
       "  1392,\n",
       "  284,\n",
       "  711,\n",
       "  345,\n",
       "  503,\n",
       "  11,\n",
       "  314,\n",
       "  1612,\n",
       "  262,\n",
       "  14442,\n",
       "  373,\n",
       "  872,\n",
       "  265,\n",
       "  198,\n",
       "  1537,\n",
       "  345,\n",
       "  821,\n",
       "  257,\n",
       "  35685,\n",
       "  11,\n",
       "  10311,\n",
       "  523,\n",
       "  4334,\n",
       "  319,\n",
       "  616,\n",
       "  736,\n",
       "  198,\n",
       "  198,\n",
       "  58,\n",
       "  1925,\n",
       "  15125,\n",
       "  60,\n",
       "  198,\n",
       "  3347,\n",
       "  12408,\n",
       "  257,\n",
       "  1256,\n",
       "  286,\n",
       "  11620,\n",
       "  198,\n",
       "  36534,\n",
       "  11,\n",
       "  10357,\n",
       "  257,\n",
       "  474,\n",
       "  15253,\n",
       "  198,\n",
       "  40,\n",
       "  1239,\n",
       "  973,\n",
       "  284,\n",
       "  15488,\n",
       "  607,\n",
       "  198,\n",
       "  10995,\n",
       "  11,\n",
       "  475,\n",
       "  326,\n",
       "  9247,\n",
       "  607,\n",
       "  198,\n",
       "  2949,\n",
       "  12,\n",
       "  505,\n",
       "  1392,\n",
       "  607,\n",
       "  9583,\n",
       "  353,\n",
       "  198,\n",
       "  3347,\n",
       "  1297,\n",
       "  502,\n",
       "  287,\n",
       "  607,\n",
       "  3850,\n",
       "  198,\n",
       "  40,\n",
       "  1183,\n",
       "  1239,\n",
       "  1683,\n",
       "  6044,\n",
       "  607,\n",
       "  198,\n",
       "  3666,\n",
       "  4508,\n",
       "  649,\n",
       "  35685,\n",
       "  198,\n",
       "  198,\n",
       "  58,\n",
       "  33890,\n",
       "  1878,\n",
       "  343,\n",
       "  60,\n",
       "  198,\n",
       "  40,\n",
       "  1392,\n",
       "  257,\n",
       "  4508,\n",
       "  649,\n",
       "  35685,\n",
       "  198,\n",
       "  1537,\n",
       "  314,\n",
       "  1422,\n",
       "  470,\n",
       "  651,\n",
       "  340,\n",
       "  422,\n",
       "  337,\n",
       "  712,\n",
       "  2047,\n",
       "  338,\n",
       "  198,\n",
       "  9360,\n",
       "  2460,\n",
       "  307,\n",
       "  10427,\n",
       "  25749,\n",
       "  475,\n",
       "  198,\n",
       "  3666,\n",
       "  827,\n",
       "  38229,\n",
       "  16194,\n",
       "  6473,\n",
       "  422,\n",
       "  262,\n",
       "  10317,\n",
       "  198,\n",
       "  6104,\n",
       "  788,\n",
       "  11,\n",
       "  314,\n",
       "  1183,\n",
       "  3758,\n",
       "  345,\n",
       "  736,\n",
       "  329,\n",
       "  257,\n",
       "  12929,\n",
       "  198,\n",
       "  17860,\n",
       "  673,\n",
       "  6332,\n",
       "  257,\n",
       "  922,\n",
       "  6877,\n",
       "  12,\n",
       "  353,\n",
       "  259,\n",
       "  357,\n",
       "  10091,\n",
       "  198,\n",
       "  2504,\n",
       "  1549,\n",
       "  423,\n",
       "  587,\n",
       "  262,\n",
       "  886,\n",
       "  198,\n",
       "  1532,\n",
       "  314,\n",
       "  1309,\n",
       "  262,\n",
       "  35685,\n",
       "  3830,\n",
       "  2402,\n",
       "  616,\n",
       "  4168,\n",
       "  198,\n",
       "  13681,\n",
       "  4746,\n",
       "  11,\n",
       "  640,\n",
       "  329,\n",
       "  257,\n",
       "  49099,\n",
       "  5466,\n",
       "  198,\n",
       "  1135,\n",
       "  787,\n",
       "  6920,\n",
       "  11,\n",
       "  517,\n",
       "  621,\n",
       "  345,\n",
       "  892,\n",
       "  198,\n",
       "  1722,\n",
       "  890,\n",
       "  355,\n",
       "  484,\n",
       "  821,\n",
       "  1913,\n",
       "  198,\n",
       "  1870,\n",
       "  262,\n",
       "  15985,\n",
       "  836,\n",
       "  470,\n",
       "  22085,\n",
       "  198,\n",
       "  1135,\n",
       "  460,\n",
       "  4341,\n",
       "  466,\n",
       "  68,\n",
       "  319,\n",
       "  257,\n",
       "  474,\n",
       "  1531,\n",
       "  466,\n",
       "  68,\n",
       "  198,\n",
       "  42323,\n",
       "  289,\n",
       "  2577,\n",
       "  1392,\n",
       "  284,\n",
       "  423,\n",
       "  8242,\n",
       "  11,\n",
       "  523,\n",
       "  198,\n",
       "  40,\n",
       "  2822,\n",
       "  262,\n",
       "  4704,\n",
       "  290,\n",
       "  1309,\n",
       "  606,\n",
       "  37982,\n",
       "  198,\n",
       "  35087,\n",
       "  340,\n",
       "  3436,\n",
       "  611,\n",
       "  345,\n",
       "  836,\n",
       "  470,\n",
       "  765,\n",
       "  284,\n",
       "  651,\n",
       "  12666,\n",
       "  503,\n",
       "  198,\n",
       "  40,\n",
       "  1053,\n",
       "  1392,\n",
       "  44395,\n",
       "  286,\n",
       "  3490,\n",
       "  8605,\n",
       "  329]}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets[564]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5680dd90-6f09-4f40-938a-2520d5631fbc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# initialized model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c24778c4-cf4d-4c8f-a065-1d2dd6fa343c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, GPT2LMHeadModel, AutoConfig\n",
    "\n",
    "config = AutoConfig.from_pretrained(\n",
    "    checkpoint,\n",
    "    vocab_size=len(tokenizer),\n",
    "    n_ctx=context_length,\n",
    "    bos_token_id=tokenizer.bos_token_id,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "247179c7-3d8f-410f-ad78-02129ca26544",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8799be43c3e477285033be15df392b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/523M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-2 size: 124.4M parameters\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(checkpoint)\n",
    "model_size = sum(t.numel() for t in model.parameters())\n",
    "print(f\"GPT-2 size: {model_size/1000**2:.1f}M parameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d72eb9-24af-4033-8cc4-ae7ba21ff44b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Data Collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ea811e0e-1124-48d9-b8b2-9c47c052f399",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer, mlm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c5e0b546-ab5a-4a06-b4fc-b2626dd3a028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([5, 500])\n",
      "attention_mask shape: torch.Size([5, 500])\n",
      "labels shape: torch.Size([5, 500])\n"
     ]
    }
   ],
   "source": [
    "out = data_collator([tokenized_datasets[i] for i in range(5)])\n",
    "for key in out:\n",
    "    print(f\"{key} shape: {out[key].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8172a129-2254-4ddb-8837-bfce0cbdc762",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = [tokenized_datasets[i] for i in range(8)]\n",
    "batch = data_collator(samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efcf0c26-0d62-4999-b03d-bb9cf8acdeb0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# login into HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0d7d3a46-00cd-4a04-ab65-17a742f36400",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09ada04184f64e82a484bf7581794ef7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29811cef-d89a-4d48-8bd5-b83ef94fcfe1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# split tokenized dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ce960e06-0355-4770-9bdc-d343d81ad3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into train and test set\n",
    "#from sklearn.model_selection import train_test_split\n",
    "\n",
    "#ds_train, ds_test = train_test_split(tokenized_datasets, test_size=0.2, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4885bcf8-d1ec-4e00-9745-152b63815712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Detected operating system as Ubuntu/focal.\n",
      "Checking for curl...\n",
      "Detected curl...\n",
      "Checking for gpg...\n",
      "Detected gpg...\n",
      "Detected apt version as 2.0.9\n",
      "Running apt-get update... done.\n",
      "Installing apt-transport-https... done.\n",
      "Installing /etc/apt/sources.list.d/github_git-lfs.list...done.\n",
      "Importing packagecloud gpg key... Packagecloud gpg key imported to /etc/apt/keyrings/github_git-lfs-archive-keyring.gpg\n",
      "done.\n",
      "Running apt-get update... done.\n",
      "\n",
      "The repository is setup! You can now install packages.\n"
     ]
    }
   ],
   "source": [
    "!curl -s https://packagecloud.io/install/repositories/github/git-lfs/script.deb.sh | sudo bash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c747d532-3a30-4851-8672-594626edbefd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "The following NEW packages will be installed:\n",
      "  git-lfs\n",
      "0 upgraded, 1 newly installed, 0 to remove and 139 not upgraded.\n",
      "Need to get 7419 kB of archives.\n",
      "After this operation, 16.0 MB of additional disk space will be used.\n",
      "Get:1 https://packagecloud.io/github/git-lfs/ubuntu focal/main amd64 git-lfs amd64 3.3.0 [7419 kB]\n",
      "Fetched 7419 kB in 1s (6633 kB/s)\n",
      "Selecting previously unselected package git-lfs.\n",
      "(Reading database ... 78560 files and directories currently installed.)\n",
      "Preparing to unpack .../git-lfs_3.3.0_amd64.deb ...\n",
      "Unpacking git-lfs (3.3.0) ...\n",
      "Setting up git-lfs (3.3.0) ...\n",
      "Git LFS initialized.\n",
      "Processing triggers for man-db (2.9.1-1) ...\n"
     ]
    }
   ],
   "source": [
    "!sudo apt-get install git-lfs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768ac34b-1c35-46d4-a895-8ea226af729f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Training Aruguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "897110f2-ff04-4d44-b4fc-dd9b431fffaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/notebooks/notebooks/hh_nlp/hiphop-ds-v2 is already a clone of https://huggingface.co/Bbrown44/hiphop-ds-v2. Make sure you pull the latest changes with `repo.git_pull()`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cuda_amp half precision backend\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"hiphop-ds-v2\",\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=5_000,\n",
    "    logging_steps=5_000,\n",
    "    gradient_accumulation_steps=32,\n",
    "    num_train_epochs=10,\n",
    "    weight_decay=0.1,\n",
    "    warmup_steps=1_000,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    learning_rate=5e-4,\n",
    "    save_steps=5_000,\n",
    "    fp16=True,\n",
    "    push_to_hub=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    args=args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=tokenized_datasets,\n",
    "    #eval_dataset=ds_test,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc709a7-1294-4de1-901c-fa7f98364757",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 1735\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 256\n",
      "  Gradient Accumulation steps = 32\n",
      "  Total optimization steps = 60\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='37' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [37/60 20:27 < 13:26, 0.03 it/s, Epoch 5.88/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49fe4d1a-2124-4673-afc8-3aa82a3aa073",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.push_to_hub()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479c6fcb-0ae0-42e6-a9ad-96bc61018261",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
